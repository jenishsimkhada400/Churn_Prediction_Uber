{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:39:41.605033Z",
     "iopub.status.busy": "2025-10-06T21:39:41.604745Z",
     "iopub.status.idle": "2025-10-06T21:39:42.489590Z",
     "shell.execute_reply": "2025-10-06T21:39:42.489264Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Python: 3.9.6 (default, Nov 11 2024, 03:15:38) \n",
      "[Clang 16.0.0 (clang-1600.0.26.6)]\n"
     ]
    }
   ],
   "source": [
    "# --- Imports & setup ---\n",
    "import os, sys, warnings, math\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "\n",
    "# plotting (kept same style so your figs look identical)\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "warnings.filterwarnings('ignore')\n",
    "plt.style.use('seaborn-v0_8')\n",
    "sns.set_palette(\"husl\")\n",
    "\n",
    "print('Python:', sys.version)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-10-06T21:39:42.503673Z",
     "iopub.status.busy": "2025-10-06T21:39:42.503557Z",
     "iopub.status.idle": "2025-10-06T21:39:47.134290Z",
     "shell.execute_reply": "2025-10-06T21:39:47.134050Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded file: ../data/ncr_ride_bookings.csv\n",
      "Detected columns (first 20): ['Date', 'Time', 'Booking ID', 'Booking Status', 'Customer ID', 'Vehicle Type', 'Pickup Location', 'Drop Location', 'Avg VTAT', 'Avg CTAT', 'Cancelled Rides by Customer', 'Reason for cancelling by Customer', 'Cancelled Rides by Driver', 'Driver Cancellation Reason', 'Incomplete Rides', 'Incomplete Rides Reason', 'Booking Value', 'Ride Distance', 'Driver Ratings', 'Customer Rating']\n",
      "\n",
      "Column mapping I will use:\n",
      "  USER   -> Customer ID\n",
      "  DATE   -> Date\n",
      "  TIME   -> Time\n",
      "  STATUS -> Booking Status\n",
      "  FARE   -> Booking Value\n",
      "  DIST   -> Ride Distance\n",
      "  VEH    -> Vehicle Type\n",
      "  PAY    -> Payment Method\n",
      "  CR     -> Customer Rating\n",
      "  DR     -> Driver Ratings\n",
      "\n",
      "Top Booking Status values:\n",
      "Booking Status\n",
      "completed                93000\n",
      "cancelled by driver      27000\n",
      "no driver found          10500\n",
      "cancelled by customer    10500\n",
      "incomplete                9000\n",
      "Name: count, dtype: int64\n",
      "\n",
      "Saving Dataset:\n",
      "==================================================\n",
      "Dataset saved to ../data/churn_dataset.pkl\n",
      "Dataset also saved to ../data/churn_dataset.csv\n",
      "\n",
      "Final Dataset Summary:\n",
      "Shape: (450, 15)\n",
      "Features: 13\n",
      "Churn rate: 0.696\n",
      "Customers: 450\n"
     ]
    }
   ],
   "source": [
    "# ==== Paths ====\n",
    "from pathlib import Path\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "DATA_DIR = Path('../data')\n",
    "RAW_CSV  = DATA_DIR / 'ncr_ride_bookings.csv'\n",
    "OUT_PKL  = DATA_DIR / 'churn_dataset.pkl'\n",
    "OUT_CSV  = DATA_DIR / 'churn_dataset.csv'\n",
    "OUT_PQ   = DATA_DIR / 'churn_dataset.parquet'\n",
    "\n",
    "assert RAW_CSV.exists(), f\"Can't find {RAW_CSV.resolve()}\"\n",
    "\n",
    "# ==== Quick sniff for column names ====\n",
    "df_head = pd.read_csv(RAW_CSV, nrows=5, low_memory=False)\n",
    "cols = df_head.columns.tolist()\n",
    "print(f\"Loaded file: {RAW_CSV}\")\n",
    "print(\"Detected columns (first 20):\", cols[:20])\n",
    "\n",
    "def pick(*cands):\n",
    "    for c in cands:\n",
    "        if c in cols:\n",
    "            return c\n",
    "    return None\n",
    "\n",
    "COL_DATE   = pick('Date', 'Ride Date', 'Booking Date')\n",
    "COL_TIME   = pick('Time', 'Ride Time', 'Booking Time')\n",
    "COL_USER   = pick('Customer ID', 'User ID', 'Customer', 'CustomerID')\n",
    "COL_STATUS = pick('Booking Status', 'Ride Status', 'Status')\n",
    "COL_FARE   = pick('Booking Value', 'Fare', 'Amount', 'Price')\n",
    "COL_DIST   = pick('Ride Distance', 'Distance (km)', 'Distance')\n",
    "COL_VEH    = pick('Vehicle Type', 'Car Type', 'Vehicle')\n",
    "COL_PAY    = pick('Payment Method', 'Payment', 'Payment Type')\n",
    "COL_CR     = pick('Customer Rating', 'Customer Ratings', 'Cust Rating')\n",
    "COL_DR     = pick('Driver Ratings', 'Driver Rating')\n",
    "\n",
    "print(\"\\nColumn mapping I will use:\")\n",
    "print(\"  USER   ->\", COL_USER)\n",
    "print(\"  DATE   ->\", COL_DATE)\n",
    "print(\"  TIME   ->\", COL_TIME)\n",
    "print(\"  STATUS ->\", COL_STATUS)\n",
    "print(\"  FARE   ->\", COL_FARE)\n",
    "print(\"  DIST   ->\", COL_DIST)\n",
    "print(\"  VEH    ->\", COL_VEH)\n",
    "print(\"  PAY    ->\", COL_PAY)\n",
    "print(\"  CR     ->\", COL_CR)\n",
    "print(\"  DR     ->\", COL_DR)\n",
    "\n",
    "# ==== Load full CSV ====\n",
    "df = pd.read_csv(RAW_CSV, low_memory=False)\n",
    "\n",
    "# ---- Build timestamp from Date + Time ----\n",
    "if COL_DATE is not None and COL_TIME is not None:\n",
    "    df['ts'] = pd.to_datetime(\n",
    "        df[COL_DATE].astype(str).str.strip() + ' ' + df[COL_TIME].astype(str).str.strip(),\n",
    "        errors='coerce'\n",
    "    )\n",
    "elif COL_DATE is not None:\n",
    "    df['ts'] = pd.to_datetime(df[COL_DATE], errors='coerce')\n",
    "elif COL_TIME is not None:\n",
    "    df['ts'] = pd.to_datetime(df[COL_TIME], errors='coerce')\n",
    "else:\n",
    "    raise ValueError(\"Could not locate a Date/Time column to build timestamps.\")\n",
    "\n",
    "# ---- Basic cleaning ----\n",
    "if COL_USER is None:\n",
    "    raise ValueError(\"Could not locate a Customer/User ID column.\")\n",
    "df = df[df[COL_USER].notna() & df['ts'].notna()].copy()\n",
    "df = df.sort_values([COL_USER, 'ts'])\n",
    "\n",
    "# ---- Status normalization; count only COMPLETED as activity ----\n",
    "if COL_STATUS is not None:\n",
    "    st_norm = df[COL_STATUS].astype(str).str.lower().str.strip()\n",
    "    print(\"\\nTop Booking Status values:\")\n",
    "    print(st_norm.value_counts().head(10))\n",
    "    COMPLETED = {\n",
    "        'completed','ride completed','complete','finished','trip completed',\n",
    "        'success','successful','ended','trip ended','completed ride'\n",
    "    }\n",
    "    df['__completed'] = st_norm.isin(COMPLETED)\n",
    "else:\n",
    "    df['__completed'] = True\n",
    "\n",
    "df_act = df[df['__completed']].copy()\n",
    "\n",
    "# ==== Per-user labeling at the PENULTIMATE ride ========================================\n",
    "LOOKBACK_D = 90     # features from 90 days before the per-user cutoff\n",
    "HORIZON_D  = 60     # label churn if NO completed ride within 60 days after cutoff\n",
    "MIN_TOTAL_COMPLETED = 2   # user must have at least 2 completed rides overall (so a penultimate exists)\n",
    "MIN_LOOKBACK_COMPLETED = 1\n",
    "\n",
    "rows = []\n",
    "user_groups = df_act.groupby(COL_USER, sort=False)\n",
    "\n",
    "for uid, g in user_groups:\n",
    "    g = g.sort_values('ts')\n",
    "    if len(g) < MIN_TOTAL_COMPLETED:\n",
    "        continue\n",
    "\n",
    "    # --- per-user cutoff = time of the penultimate completed ride ---\n",
    "    # (If exactly 2 rides, this is the first ride; if >2, it's the second-to-last.)\n",
    "    ref_end = g['ts'].iloc[-2]\n",
    "\n",
    "    # --- lookback window ends at ref_end; start LOOKBACK_D days before ---\n",
    "    lb_start = ref_end - pd.Timedelta(days=LOOKBACK_D)\n",
    "    in_win = g[(g['ts'] > lb_start) & (g['ts'] <= ref_end)].copy()\n",
    "    if len(in_win) < MIN_LOOKBACK_COMPLETED:\n",
    "        continue\n",
    "\n",
    "    # --- future window for label: (ref_end, ref_end + HORIZON_D] ---\n",
    "    future = g[(g['ts'] > ref_end) & (g['ts'] <= ref_end + pd.Timedelta(days=HORIZON_D))]\n",
    "\n",
    "    # ---- features from lookback ----\n",
    "    recency_days = (ref_end - in_win['ts'].max()).total_seconds() / (3600*24)\n",
    "    rides_lb = len(in_win)\n",
    "\n",
    "    row = {\n",
    "        'Customer ID': uid,\n",
    "        'num__recency_days': recency_days,\n",
    "        'num__rides_lookback': rides_lb,\n",
    "        'ref_end': ref_end\n",
    "    }\n",
    "\n",
    "    if COL_FARE in in_win.columns:\n",
    "        fares = pd.to_numeric(in_win[COL_FARE], errors='coerce')\n",
    "        row['num__fare_sum_lb']  = fares.sum()\n",
    "        row['num__fare_mean_lb'] = fares.mean()\n",
    "    if COL_DIST in in_win.columns:\n",
    "        dd = pd.to_numeric(in_win[COL_DIST], errors='coerce')\n",
    "        row['num__dist_sum_lb']  = dd.sum()\n",
    "        row['num__dist_mean_lb'] = dd.mean()\n",
    "    if COL_CR in in_win.columns:\n",
    "        row['num__customer_rating_mean_lb'] = pd.to_numeric(in_win[COL_CR], errors='coerce').mean()\n",
    "    if COL_DR in in_win.columns:\n",
    "        row['num__driver_rating_mean_lb'] = pd.to_numeric(in_win[COL_DR], errors='coerce').mean()\n",
    "\n",
    "    # time-of-day mix\n",
    "    hr = in_win['ts'].dt.hour\n",
    "    row['num__pct_morning'] = ((hr>=5)&(hr<12)).mean()\n",
    "    row['num__pct_evening'] = ((hr>=17)&(hr<22)).mean()\n",
    "    row['num__pct_night']   = ((hr>=22)|(hr<5)).mean()\n",
    "\n",
    "    # most-used vehicle\n",
    "    if COL_VEH in in_win.columns and in_win[COL_VEH].notna().any():\n",
    "        row['cat__most_used_vehicle_lb'] = in_win[COL_VEH].value_counts().idxmax()\n",
    "\n",
    "    # payment diversity\n",
    "    if COL_PAY in in_win.columns:\n",
    "        row['num__payment_diversity_lb'] = in_win[COL_PAY].nunique(dropna=True) / len(in_win)\n",
    "\n",
    "    # ---- label ----\n",
    "    row['churn_30d'] = int(len(future) == 0)  # 1 = churn (no completed ride within HORIZON_D)\n",
    "    rows.append(row)\n",
    "\n",
    "final = pd.DataFrame(rows)\n",
    "\n",
    "# tidy & save\n",
    "num_cols = [c for c in final.columns if c.startswith('num__')]\n",
    "cat_cols = [c for c in final.columns if c.startswith('cat__')]\n",
    "if 'ref_end' in final.columns:\n",
    "    final.drop(columns=['ref_end'], inplace=True, errors='ignore')\n",
    "\n",
    "OUT_PKL.parent.mkdir(parents=True, exist_ok=True)\n",
    "final.to_pickle(OUT_PKL)\n",
    "final.to_csv(OUT_CSV, index=False)\n",
    "try:\n",
    "    final.to_parquet(OUT_PQ, index=False)\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# summary\n",
    "print(\"\\nSaving Dataset:\")\n",
    "print(\"=\"*50)\n",
    "print(f\"Dataset saved to {OUT_PKL}\")\n",
    "print(f\"Dataset also saved to {OUT_CSV}\")\n",
    "\n",
    "print(\"\\nFinal Dataset Summary:\")\n",
    "print(\"Shape:\", final.shape)\n",
    "print(\"Features:\", len(num_cols) + len(cat_cols))\n",
    "print(\"Churn rate:\", round(final['churn_30d'].mean(), 3) if len(final) else float('nan'))\n",
    "print(\"Customers:\", len(final))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
